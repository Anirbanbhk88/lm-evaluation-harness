{"config": {"settings": {"experiment_id": "2024-11-27__10-15-19_f28a29ef", "config_file_path": "/raid/s3/opengptx/alexj/llm_gym/modalities/modalities/data/checkpoints/2024-11-27__10-01-38_fed79d73/config_lorem_ipsum.yaml", "referencing_keys": {"sample_key": "input_ids", "target_key": "target_ids"}, "training": {"training_log_interval_in_steps": 2, "checkpointing_interval_in_steps": 4, "evaluation_interval_in_steps": 2, "global_num_seen_tokens": 0, "activation_checkpointing_modules": ["GPT2Block"], "gradient_acc_steps": 2, "local_train_micro_batch_size": 1, "sequence_length": 256}, "cuda_env": {"local_rank": 1, "global_rank": 1, "world_size": 2}, "paths": {"checkpointing_path": "data/checkpoints"}}, "collate_fn": {"component_key": "collate_fn", "variant_key": "gpt_2_llm_collator", "config": {"sample_key": "input_ids", "target_key": "target_ids"}}, "train_dataset": {"component_key": "dataset", "variant_key": "packed_mem_map_dataset_continuous", "config": {"raw_data_path": "./data/lorem_ipsum.pbin", "sequence_length": 256, "sample_key": "input_ids"}}, "train_dataloader": {"component_key": "data_loader", "variant_key": "default", "config": {"num_workers": 2, "pin_memory": true, "shuffle": false, "dataloader_tag": "train", "dataset": {"instance_key": "train_dataset", "pass_type": "BY_REFERENCE"}, "batch_sampler": {"component_key": "batch_sampler", "variant_key": "default", "config": {"batch_size": 1, "drop_last": true, "sampler": {"component_key": "sampler", "variant_key": "distributed_sampler", "config": {"rank": 1, "num_replicas": 2, "shuffle": true, "dataset": {"instance_key": "train_dataset", "pass_type": "BY_REFERENCE"}}}}}, "collate_fn": {"instance_key": "collate_fn", "pass_type": "BY_REFERENCE"}}}, "val_dataloader": {"component_key": "data_loader", "variant_key": "default", "config": {"num_workers": 2, "pin_memory": true, "shuffle": false, "dataloader_tag": "val", "dataset": {"instance_key": "train_dataset", "pass_type": "BY_REFERENCE"}, "batch_sampler": {"component_key": "batch_sampler", "variant_key": "default", "config": {"batch_size": 4, "drop_last": true, "sampler": {"component_key": "sampler", "variant_key": "distributed_sampler", "config": {"rank": 1, "num_replicas": 2, "shuffle": false, "dataset": {"instance_key": "train_dataset", "pass_type": "BY_REFERENCE"}}}}}, "collate_fn": {"instance_key": "collate_fn", "pass_type": "BY_REFERENCE"}}}, "test_dataloader": {"component_key": "data_loader", "variant_key": "default", "config": {"num_workers": 2, "pin_memory": true, "shuffle": false, "dataloader_tag": "test", "dataset": {"instance_key": "train_dataset", "pass_type": "BY_REFERENCE"}, "batch_sampler": {"component_key": "batch_sampler", "variant_key": "default", "config": {"batch_size": 2, "drop_last": true, "sampler": {"component_key": "sampler", "variant_key": "distributed_sampler", "config": {"rank": 1, "num_replicas": 2, "shuffle": false, "dataset": {"instance_key": "train_dataset", "pass_type": "BY_REFERENCE"}}}}}, "collate_fn": {"instance_key": "collate_fn", "pass_type": "BY_REFERENCE"}}}, "eval_dataloaders": [{"instance_key": "val_dataloader", "pass_type": "BY_REFERENCE"}, {"instance_key": "test_dataloader", "pass_type": "BY_REFERENCE"}], "checkpoint_saving": {"component_key": "checkpoint_saving", "variant_key": "default", "config": {"checkpoint_saving_strategy": {"component_key": "checkpoint_saving_strategy", "variant_key": "save_k_most_recent_checkpoints_strategy", "config": {"k": -1}}, "checkpoint_saving_execution": {"component_key": "checkpoint_saving_execution", "variant_key": "fsdp", "config": {"checkpoint_path": "data/checkpoints", "global_rank": 1, "experiment_id": "2024-11-27__10-15-19_f28a29ef", "get_num_tokens_from_num_steps_callable": {"component_key": "number_conversion", "variant_key": "num_tokens_from_num_steps_callable", "config": {"num_ranks": 2, "local_micro_batch_size": 1, "sequence_length": 256}}}}}}, "loss_fn": {"component_key": "loss", "variant_key": "clm_cross_entropy_loss", "config": {"target_key": "target_ids", "prediction_key": "logits"}}, "wrapped_model": {"component_key": "model", "variant_key": "fsdp_wrapped", "config": {"model": {"instance_key": "model", "pass_type": "BY_REFERENCE"}, "sync_module_states": true, "mixed_precision_settings": "BF_16", "sharding_strategy": "FULL_SHARD", "block_names": ["GPT2Block"]}}, "model": {"component_key": "model", "variant_key": "model_initialized", "config": {"model": {"instance_key": "model_raw", "pass_type": "BY_REFERENCE"}, "model_initializer": {"component_key": "model_initialization", "variant_key": "composed", "config": {"model_type": "gpt2", "weight_init_type": "scaled", "mean": 0.0, "std": 0.02, "num_layers": 2}}}}, "model_raw": {"component_key": "model", "variant_key": "gpt2", "config": {"sample_key": "input_ids", "poe_type": "NOPE", "sequence_length": 256, "prediction_key": "logits", "vocab_size": 50304, "n_layer": 2, "n_head_q": 8, "n_head_kv": 4, "ffn_hidden": 128, "n_embd": 128, "dropout": 0.0, "bias": true, "attention_config": {"qkv_transforms": [{"type_hint": "RotaryTransform", "config": {"n_embd": 128, "n_head": 8, "seq_length_dim": -2}}]}, "attention_implementation": "manual", "activation_type": "swiglu", "attention_norm": {"component_key": "layer_norm", "variant_key": "rms_norm", "config": {"ndim": 128, "bias": true, "epsilon": 1e-05}}, "ffn_norm": {"component_key": "layer_norm", "variant_key": "rms_norm", "config": {"ndim": 128, "bias": true, "epsilon": 1e-05}}, "lm_head_norm": {"component_key": "layer_norm", "variant_key": "rms_norm", "config": {"ndim": 128, "bias": true, "epsilon": 1e-05}}}}, "scheduler": {"component_key": "scheduler", "variant_key": "onecycle_lr", "config": {"optimizer": {"instance_key": "optimizer", "pass_type": "BY_REFERENCE"}, "max_lr": 0.0006, "div_factor": 10, "final_div_factor": 1, "total_steps": 16, "pct_start": 0.01, "anneal_strategy": "cos"}}, "optimizer": {"component_key": "optimizer", "variant_key": "adam_w", "config": {"lr": 0.0001, "betas": [0.9, 0.95], "eps": 1e-08, "weight_decay": 0.1, "weight_decay_groups_excluded": ["embedding", "layernorm"], "wrapped_model": {"instance_key": "wrapped_model", "pass_type": "BY_REFERENCE"}}}, "gradient_clipper": {"component_key": "gradient_clipper", "variant_key": "fsdp", "config": {"wrapped_model": {"instance_key": "wrapped_model", "pass_type": "BY_REFERENCE"}, "norm_type": "P2_NORM", "max_norm": 1.0}}, "batch_progress_subscriber": {"component_key": "progress_subscriber", "variant_key": "rich", "config": {"global_rank": 1, "global_num_seen_steps": {"component_key": "number_conversion", "variant_key": "num_steps_from_num_tokens", "config": {"num_ranks": 2, "local_micro_batch_size": 1, "global_num_tokens": 0, "sequence_length": 256}}, "gradient_acc_steps": 2, "train_dataloader": {"instance_key": "train_dataloader", "pass_type": "BY_REFERENCE"}, "eval_dataloaders": {"instance_key": "eval_dataloaders", "pass_type": "BY_REFERENCE"}}}, "evaluation_subscriber": {"component_key": "results_subscriber", "variant_key": "wandb", "config": {"global_rank": 1, "project": "modalities_lorem_ipsum", "mode": "OFFLINE", "experiment_id": "2024-11-27__10-15-19_f28a29ef", "directory": "wandb_storage", "config_file_path": "/raid/s3/opengptx/alexj/llm_gym/modalities/modalities/data/checkpoints/2024-11-27__10-01-38_fed79d73/config_lorem_ipsum.yaml"}}, "checkpointed_model": {"component_key": "model", "variant_key": "checkpointed", "config": {"checkpoint_loading": {"component_key": "checkpoint_loading", "variant_key": "torch", "config": {"device": 0, "precision": "BF_16"}}, "model": {"instance_key": "model", "pass_type": "BY_REFERENCE"}, "checkpoint_path": "/raid/s3/opengptx/alexj/llm_gym/modalities/modalities/data/checkpoints/2024-11-27__10-01-38_fed79d73/eid_2024-11-27__10-01-38_fed79d73-model-num_steps_4-num_tokens_2048.bin"}}}, "model_type": "modalities"}